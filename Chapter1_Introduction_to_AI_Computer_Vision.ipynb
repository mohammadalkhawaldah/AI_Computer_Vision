{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9X-gPndrLpit"
      },
      "source": [
        "# Chapter 1 ‚Äî Introduction to AI Computer Vision (Mechatronics Systems View)\n",
        "**Course:** Special Topics in Mechatronics Engineering (AI + Computer Vision + Intelligent Controllers)  \n",
        "**Instructor:** Dr. Mohammad Al Khawaldah  \n",
        "**Notebook type:** Lecture + Lab (interactive)  \n",
        "**Last updated:** 2026-02-16\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ Learning Outcomes\n",
        "By the end of Chapter 1, you will be able to:\n",
        "\n",
        "1. Explain the full **Vision‚ÜíDecision‚ÜíController** pipeline (system engineering, not model-only).\n",
        "2. Define core terms precisely: **model, training, inference, dataset, labels, classes, confidence, threshold, NMS, tracking, domain shift, latency**.\n",
        "3. Run a complete example application (frame ‚Üí inference ‚Üí decision gate ‚Üí ‚Äúactuator command‚Äù + evidence logging).\n",
        "4. Ask the right **engineering questions** and identify common **failure modes** in industrial vision systems.\n",
        "\n",
        "> In mechatronics, the model is only a part of the system. The rest is engineering."
      ],
      "id": "9X-gPndrLpit"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lou1RGpQLpiw"
      },
      "source": [
        "---\n",
        "# 1) Introduction: AI Computer Vision in Mechatronics\n",
        "\n",
        "Computer Vision transforms raw pixels into structured understanding (objects, states, defects, motion).  \n",
        "Mechatronics turns that understanding into **actions** that affect the physical world.\n",
        "\n",
        "### Why it is different from ‚Äúpure AI‚Äù\n",
        "A real mechatronics vision system must satisfy:\n",
        "- **Latency constraints** (real-time control, moving targets, conveyor speed)\n",
        "- **Safety constraints** (false alarms create ‚Äúalarm fatigue‚Äù; missed detections can cause accidents)\n",
        "- **Hardware constraints** (CPU/GPU, memory, power, edge vs cloud)\n",
        "- **Environmental variation** (lighting, dust, glare, camera shift) ‚Üí domain shift\n",
        "\n",
        "We do not just train models ‚Äî we design **end-to-end systems**."
      ],
      "id": "Lou1RGpQLpiw"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ent6ec2hLpiw"
      },
      "source": [
        "---\n",
        "# 2) The Complete AI Vision Pipeline (End-to-End System)\n",
        "\n",
        "Canonical pipeline in industrial mechatronics:\n",
        "\n",
        "**Sensor ‚Üí Preprocessing ‚Üí Model Inference ‚Üí Post-processing ‚Üí Decision Logic ‚Üí Controller Interface ‚Üí Actuator ‚Üí Logging**\n",
        "\n",
        "You must be able to explain what happens at each step, and what can go wrong."
      ],
      "id": "ent6ec2hLpiw"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "ZwNgXTK-Lpix",
        "outputId": "80727861-5e13-425a-bfb5-1708513dc034"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: vision_pipeline Pages: 1 -->\n<svg width=\"1246pt\" height=\"102pt\"\n viewBox=\"0.00 0.00 1246.00 102.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 98)\">\n<title>vision_pipeline</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-98 1242,-98 1242,4 -4,4\"/>\n<!-- S -->\n<g id=\"node1\" class=\"node\">\n<title>S</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"111,-66 0,-66 0,-28 111,-28 111,-66\"/>\n<text text-anchor=\"middle\" x=\"55.5\" y=\"-50.8\" font-family=\"Times,serif\" font-size=\"14.00\">Sensor</text>\n<text text-anchor=\"middle\" x=\"55.5\" y=\"-35.8\" font-family=\"Times,serif\" font-size=\"14.00\">(Camera/Stream)</text>\n</g>\n<!-- P -->\n<g id=\"node2\" class=\"node\">\n<title>P</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"297,-66 147,-66 147,-28 297,-28 297,-66\"/>\n<text text-anchor=\"middle\" x=\"222\" y=\"-50.8\" font-family=\"Times,serif\" font-size=\"14.00\">Preprocessing</text>\n<text text-anchor=\"middle\" x=\"222\" y=\"-35.8\" font-family=\"Times,serif\" font-size=\"14.00\">(resize, normalize, ROI)</text>\n</g>\n<!-- S&#45;&gt;P -->\n<g id=\"edge1\" class=\"edge\">\n<title>S&#45;&gt;P</title>\n<path fill=\"none\" stroke=\"black\" d=\"M111.28,-47C119.47,-47 128.08,-47 136.72,-47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"136.84,-50.5 146.84,-47 136.84,-43.5 136.84,-50.5\"/>\n</g>\n<!-- M -->\n<g id=\"node3\" class=\"node\">\n<title>M</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"443,-66 333,-66 333,-28 443,-28 443,-66\"/>\n<text text-anchor=\"middle\" x=\"388\" y=\"-50.8\" font-family=\"Times,serif\" font-size=\"14.00\">Model Inference</text>\n<text text-anchor=\"middle\" x=\"388\" y=\"-35.8\" font-family=\"Times,serif\" font-size=\"14.00\">(CLS/DET/SEG)</text>\n</g>\n<!-- P&#45;&gt;M -->\n<g id=\"edge2\" class=\"edge\">\n<title>P&#45;&gt;M</title>\n<path fill=\"none\" stroke=\"black\" d=\"M297.32,-47C305.67,-47 314.11,-47 322.32,-47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"322.56,-50.5 332.56,-47 322.56,-43.5 322.56,-50.5\"/>\n</g>\n<!-- PP -->\n<g id=\"node4\" class=\"node\">\n<title>PP</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"644,-66 479,-66 479,-28 644,-28 644,-66\"/>\n<text text-anchor=\"middle\" x=\"561.5\" y=\"-50.8\" font-family=\"Times,serif\" font-size=\"14.00\">Post&#45;processing</text>\n<text text-anchor=\"middle\" x=\"561.5\" y=\"-35.8\" font-family=\"Times,serif\" font-size=\"14.00\">(threshold, NMS, tracking)</text>\n</g>\n<!-- M&#45;&gt;PP -->\n<g id=\"edge3\" class=\"edge\">\n<title>M&#45;&gt;PP</title>\n<path fill=\"none\" stroke=\"black\" d=\"M443.26,-47C451.37,-47 459.92,-47 468.55,-47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"468.71,-50.5 478.71,-47 468.71,-43.5 468.71,-50.5\"/>\n</g>\n<!-- D -->\n<g id=\"node5\" class=\"node\">\n<title>D</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"847,-66 680,-66 680,-28 847,-28 847,-66\"/>\n<text text-anchor=\"middle\" x=\"763.5\" y=\"-50.8\" font-family=\"Times,serif\" font-size=\"14.00\">Decision Logic</text>\n<text text-anchor=\"middle\" x=\"763.5\" y=\"-35.8\" font-family=\"Times,serif\" font-size=\"14.00\">(state machine, safety gate)</text>\n</g>\n<!-- PP&#45;&gt;D -->\n<g id=\"edge4\" class=\"edge\">\n<title>PP&#45;&gt;D</title>\n<path fill=\"none\" stroke=\"black\" d=\"M644.14,-47C652.6,-47 661.24,-47 669.81,-47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"669.83,-50.5 679.83,-47 669.83,-43.5 669.83,-50.5\"/>\n</g>\n<!-- C -->\n<g id=\"node6\" class=\"node\">\n<title>C</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"1047,-94 883,-94 883,-56 1047,-56 1047,-94\"/>\n<text text-anchor=\"middle\" x=\"965\" y=\"-78.8\" font-family=\"Times,serif\" font-size=\"14.00\">Controller Interface</text>\n<text text-anchor=\"middle\" x=\"965\" y=\"-63.8\" font-family=\"Times,serif\" font-size=\"14.00\">(serial/MQTT/REST/ROS)</text>\n</g>\n<!-- D&#45;&gt;C -->\n<g id=\"edge5\" class=\"edge\">\n<title>D&#45;&gt;C</title>\n<path fill=\"none\" stroke=\"black\" d=\"M847.08,-58.59C855.56,-59.78 864.2,-60.99 872.77,-62.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"872.37,-65.67 882.76,-63.6 873.35,-58.74 872.37,-65.67\"/>\n</g>\n<!-- L -->\n<g id=\"node8\" class=\"node\">\n<title>L</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"1030,-38 900,-38 900,0 1030,0 1030,-38\"/>\n<text text-anchor=\"middle\" x=\"965\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\">Logging</text>\n<text text-anchor=\"middle\" x=\"965\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\">(evidence + metrics)</text>\n</g>\n<!-- D&#45;&gt;L -->\n<g id=\"edge7\" class=\"edge\">\n<title>D&#45;&gt;L</title>\n<path fill=\"none\" stroke=\"black\" d=\"M847.08,-35.41C861.23,-33.42 875.85,-31.37 889.76,-29.42\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"890.33,-32.87 899.75,-28.02 889.36,-25.94 890.33,-32.87\"/>\n</g>\n<!-- A -->\n<g id=\"node7\" class=\"node\">\n<title>A</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"1238,-94 1083,-94 1083,-56 1238,-56 1238,-94\"/>\n<text text-anchor=\"middle\" x=\"1160.5\" y=\"-78.8\" font-family=\"Times,serif\" font-size=\"14.00\">Actuator</text>\n<text text-anchor=\"middle\" x=\"1160.5\" y=\"-63.8\" font-family=\"Times,serif\" font-size=\"14.00\">(LED/buzzer/gate/motor)</text>\n</g>\n<!-- C&#45;&gt;A -->\n<g id=\"edge6\" class=\"edge\">\n<title>C&#45;&gt;A</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1047.22,-75C1055.6,-75 1064.14,-75 1072.59,-75\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1072.81,-78.5 1082.81,-75 1072.81,-71.5 1072.81,-78.5\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.graphs.Digraph at 0x7d7c38e06d20>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# =========================================================\n",
        "# 2.1 Flowchart diagram (auto-generated) using Graphviz\n",
        "# =========================================================\n",
        "!pip -q install graphviz\n",
        "\n",
        "from graphviz import Digraph\n",
        "\n",
        "g = Digraph(\"vision_pipeline\", format=\"png\")\n",
        "g.attr(rankdir=\"LR\", fontsize=\"12\")\n",
        "\n",
        "g.node(\"S\", \"Sensor\\n(Camera/Stream)\", shape=\"box\")\n",
        "g.node(\"P\", \"Preprocessing\\n(resize, normalize, ROI)\", shape=\"box\")\n",
        "g.node(\"M\", \"Model Inference\\n(CLS/DET/SEG)\", shape=\"box\")\n",
        "g.node(\"PP\", \"Post-processing\\n(threshold, NMS, tracking)\", shape=\"box\")\n",
        "g.node(\"D\", \"Decision Logic\\n(state machine, safety gate)\", shape=\"box\")\n",
        "g.node(\"C\", \"Controller Interface\\n(serial/MQTT/REST/ROS)\", shape=\"box\")\n",
        "g.node(\"A\", \"Actuator\\n(LED/buzzer/gate/motor)\", shape=\"box\")\n",
        "g.node(\"L\", \"Logging\\n(evidence + metrics)\", shape=\"box\")\n",
        "\n",
        "g.edges([(\"S\",\"P\"), (\"P\",\"M\"), (\"M\",\"PP\"), (\"PP\",\"D\"), (\"D\",\"C\"), (\"C\",\"A\"), (\"D\",\"L\")])\n",
        "\n",
        "g"
      ],
      "id": "ZwNgXTK-Lpix"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPmzJFGNLpix"
      },
      "source": [
        "### Engineering interpretation\n",
        "- Preprocessing changes both accuracy and latency.\n",
        "- Post-processing prevents duplicated boxes (NMS) and stabilizes decisions (temporal smoothing).\n",
        "- Decision logic is where safety policies live (e.g., ‚Äú3 consecutive frames required‚Äù).\n",
        "- Logging is mandatory for audits and debugging."
      ],
      "id": "wPmzJFGNLpix"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrVspcFiLpiy"
      },
      "source": [
        "---\n",
        "# 3) Industrial Applications (Detailed)\n",
        "\n",
        "## A) Truck Load Compliance Inspection\n",
        "**Goal:** Detect whether a truck bed is covered/uncovered/irregular and optionally classify visible load type.\n",
        "\n",
        "**Inputs:** fixed CCTV stream (RTSP). Sometimes a separate ANPR camera provides plate number as API.  \n",
        "**Outputs:** violation/no-violation event + evidence snapshot + optional actuator (gate/buzzer).\n",
        "\n",
        "**System steps:**\n",
        "1. Detect truck/bed region (DET) ‚Üí crop ROI for better accuracy.\n",
        "2. Classify cover state (CLS) OR segment cover/exposed regions (SEG).\n",
        "3. Temporal gate: stable violation for N frames to avoid ‚Äúone-frame noise‚Äù.\n",
        "4. Merge repeated detections into one event per truck using tracking ID.\n",
        "5. Log timestamp, confidence, snapshot, and plate ID (fusion).\n",
        "\n",
        "**Hard real-world conditions:**\n",
        "glare, shadows, night IR, motion blur, camera shift (domain shift), multiple trucks, occlusions.\n",
        "\n",
        "## B) PPE Safety (Helmet detection)\n",
        "Detect person + helmet; alarm if person without helmet persists >2 seconds (avoid alarm spam).\n",
        "\n",
        "## C) Conveyor Quality Inspection\n",
        "Detect defects/missing parts and trigger reject actuator (air jet/robot arm). Strict latency.\n",
        "\n",
        "## D) Drone Vision\n",
        "Detect targets from moving camera. Bandwidth + motion blur constraints."
      ],
      "id": "ZrVspcFiLpiy"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9b5CU2dLpiy"
      },
      "source": [
        "---\n",
        "# 4) Definitions (Core Terms)\n",
        "\n",
        "### Model\n",
        "A model is a function **fŒ∏(x)** mapping input image x ‚Üí output y. Œ∏ are learned parameters.\n",
        "\n",
        "### Training vs Inference\n",
        "- Training: learn Œ∏ from labeled dataset by minimizing a loss.\n",
        "- Inference: run trained model on new frames ‚Üí predictions.\n",
        "\n",
        "### Dataset, Labels, Classes\n",
        "- Dataset: samples (images/frames) + labels.\n",
        "- Label/Annotation: ground truth (class / boxes / masks).\n",
        "- Class: category name (‚Äúcovered‚Äù, ‚Äúuncovered‚Äù, ‚Äúhelmet‚Äù, ‚Ä¶).\n",
        "\n",
        "### Confidence & Threshold\n",
        "- Confidence: model score for prediction (not always calibrated probability).\n",
        "- Threshold: accept prediction only if score ‚â• threshold.\n",
        "\n",
        "### NMS\n",
        "Removes duplicated overlapping boxes (detection).\n",
        "\n",
        "### Tracking\n",
        "Persistent object IDs across frames; prevents multiple events per same object.\n",
        "\n",
        "### Overfitting\n",
        "Train ‚Üë, val ‚Üì. Model memorizes.\n",
        "\n",
        "### Domain shift\n",
        "Training distribution ‚â† deployment distribution (angle/lighting/weather). #1 industrial failure.\n",
        "\n",
        "### Latency\n",
        "Capture ‚Üí decision time. Must meet real-time needs."
      ],
      "id": "c9b5CU2dLpiy"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eNTNUW7Lpi0"
      },
      "source": [
        "---\n",
        "# 5) Key Questions (Engineering Checklist)\n",
        "\n",
        "### System questions\n",
        "1. Edge vs cloud inference? What if network fails?\n",
        "2. End-to-end latency budget? Required FPS?\n",
        "3. Cost of false positives vs false negatives?\n",
        "4. Tracking needed to enforce ‚Äúone event per object‚Äù?\n",
        "5. What evidence must be stored (snapshot + confidence + reason)?\n",
        "\n",
        "### Data questions\n",
        "1. Does dataset match deployment camera angle/lighting?\n",
        "2. Is dataset balanced?\n",
        "3. Are labels consistent?\n",
        "4. Do we have rare critical cases (night/rain/occlusion)?\n",
        "\n",
        "### Model questions\n",
        "1. Need classification/detection/segmentation?\n",
        "2. Smallest model meeting accuracy+speed?\n",
        "3. Which threshold matches safety policy?"
      ],
      "id": "7eNTNUW7Lpi0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NgK36PqLpi0"
      },
      "source": [
        "---\n",
        "# 6) Failure Modes (Real-World)\n",
        "\n",
        "### Data failures\n",
        "Label noise, dataset bias (day-only), leakage, missing corner cases.\n",
        "\n",
        "### Model failures\n",
        "Overfitting, slow model (latency), poor confidence calibration.\n",
        "\n",
        "### Deployment failures\n",
        "Camera moved, dirty lens, compression artifacts, new unseen objects (domain drift).\n",
        "\n",
        "### System logic failures\n",
        "No temporal smoothing, no cooldown, no tracking, no logging."
      ],
      "id": "9NgK36PqLpi0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQAkrleaLpi0"
      },
      "source": [
        "---\n",
        "# 7) Exercises (Graded)\n",
        "\n",
        "## Exercise 1 ‚Äî Threshold trade-off\n",
        "Change `policy.threshold` to 0.80 and rerun. Explain what happens (FP vs FN).\n",
        "\n",
        "## Exercise 2 ‚Äî Stronger temporal gating\n",
        "Set `min_consecutive` to 3. Add more frames to `frame_paths`. Observe stability.\n",
        "\n",
        "## Exercise 3 ‚Äî Evidence\n",
        "Open the `evidence/` folder and inspect saved files. Why is this mandatory in compliance systems?\n",
        "\n",
        "## Exercise 4 ‚Äî Design (written)\n",
        "Pick one application (truck/PPE/conveyor/drone) and write:\n",
        "- pipeline blocks\n",
        "- where domain shift can happen\n",
        "- what you will log as evidence"
      ],
      "id": "aQAkrleaLpi0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tA4xZ177Lpi0"
      },
      "source": [
        "---\n",
        "# ‚úÖ Chapter 1 Summary\n",
        "You learned:\n",
        "- AI vision is a **system**, not only a model.\n",
        "- Key terms and how they connect in the pipeline.\n",
        "- Engineering questions + failure modes.\n",
        "\n",
        "üëâ Next: Module 2 ‚Äî Image Classification (dataset, training, evaluation, deployment)."
      ],
      "id": "tA4xZ177Lpi0"
    }
  ],
  "metadata": {
    "colab": {
      "name": "Chapter1_Introduction_to_AI_Computer_Vision.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}